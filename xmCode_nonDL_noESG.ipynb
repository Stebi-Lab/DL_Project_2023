{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL project \n",
    "## Prediction or Share price based on previous share price and ESG factor - NON DL model\n",
    "CSI 300 company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 define the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_nonDL(X_train, y_train,\n",
    "                  X_test, y_test):\n",
    "    test_loss = 0\n",
    "\n",
    "    import sklearn.metrics as metrics\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('regressor', HistGradientBoostingRegressor(random_state=42))])\n",
    "\n",
    "    param_grid = [{\n",
    "                    'regressor__max_depth':  np.array([3, 5]),\n",
    "                    'regressor__l2_regularization': np.array([0, 1])\n",
    "                }]\n",
    "\n",
    "    grid = GridSearchCV(estimator=pipeline,\n",
    "                        param_grid=param_grid,\n",
    "                        scoring='neg_mean_squared_error',\n",
    "                        cv=5,\n",
    "                        verbose=2,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "    grid_result = grid.fit(X_train, y_train.ravel())\n",
    "    pipelineFinal = grid_result.best_estimator_\n",
    "\n",
    "    scores = cross_val_score(pipelineFinal,\n",
    "                            X_train,\n",
    "                            y_train.ravel(),\n",
    "                            scoring='neg_mean_squared_error',\n",
    "                            cv=5,\n",
    "                            verbose=2,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "\n",
    "    #print(\"Cross-validation score is {score:.2f}, standard deviation is {err:.2f}\" .format(score=scores.mean(), err=scores.std()))\n",
    "\n",
    "\n",
    "    test_preds = pipelineFinal.predict(X_test)\n",
    "    test_loss = mean_squared_error(test_preds, y_test)\n",
    "    '''\n",
    "    for epoch in range(n_epochs):\n",
    "        lstm.train()\n",
    "        outputs = lstm.forward(X_train) # forward pass\n",
    "        optimiser.zero_grad() # calculate the gradient, manually setting to 0\n",
    "        # obtain the loss function\n",
    "        loss = loss_fn(outputs, y_train)\n",
    "        loss.backward() # calculates the loss of the loss function\n",
    "        optimiser.step() # improve from loss, i.e backprop\n",
    "      \n",
    "        # test loss\n",
    "        lstm.eval()\n",
    "        test_preds = lstm(X_test)\n",
    "        test_loss = loss_fn(test_preds, y_test)\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch: %d, train loss: %1.5f, test loss: %1.5f\" % (epoch, \n",
    "                                                                      loss.item(), \n",
    "                                                                      test_loss.item()))\n",
    "       '''         \n",
    "\n",
    "    #return test_loss.item()\n",
    "    return test_loss, pipelineFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nb/j2jdrzs95md121c1h0mksmz80000gq/T/ipykernel_18830/1506395074.py:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df2019 = pd.read_excel('data_feature_csi_2019.xlsx', index_col = 'Company_code', parse_dates=True)\n",
      "/var/folders/nb/j2jdrzs95md121c1h0mksmz80000gq/T/ipykernel_18830/1506395074.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df2020 = pd.read_excel('data_feature_csi_2020.xlsx', index_col = 'Company_code', parse_dates=True)\n",
      "/var/folders/nb/j2jdrzs95md121c1h0mksmz80000gq/T/ipykernel_18830/1506395074.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df2021 = pd.read_excel('data_feature_csi_2021.xlsx', index_col = 'Company_code', parse_dates=True)\n",
      "/var/folders/nb/j2jdrzs95md121c1h0mksmz80000gq/T/ipykernel_18830/1506395074.py:18: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df2022 = pd.read_excel('data_feature_csi_2022.xlsx', index_col = 'Company_code', parse_dates=True)\n"
     ]
    }
   ],
   "source": [
    "ESG = False\n",
    "input_size = 6 # number of features (without ESG 6 with 19)\n",
    "if ESG:\n",
    "    input_size = 19\n",
    "\n",
    "''' not used in NonDLmodel\n",
    "lstm = LSTM(num_classes, \n",
    "        input_size, \n",
    "        hidden_size, \n",
    "        num_layers)\n",
    "loss_fn = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimiser = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "'''\n",
    "\n",
    "df2019 = pd.read_excel('data_feature_csi_2019.xlsx', index_col = 'Company_code', parse_dates=True)\n",
    "df2020 = pd.read_excel('data_feature_csi_2020.xlsx', index_col = 'Company_code', parse_dates=True)\n",
    "df2021 = pd.read_excel('data_feature_csi_2021.xlsx', index_col = 'Company_code', parse_dates=True)\n",
    "df2022 = pd.read_excel('data_feature_csi_2022.xlsx', index_col = 'Company_code', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define training iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainingIteration(plotting, f, filename):\n",
    "\n",
    "\n",
    "    preview = 241 # How many previous days to use for prediction\n",
    "    predict = 1 # how many values in the future to predict\n",
    "    futureStep = 241 # how far in the future to predict\n",
    "\n",
    "    total = preview+predict\n",
    "\n",
    "\n",
    "\n",
    "    df = pd.read_csv(f, index_col = 'Date', parse_dates=True)\n",
    "\n",
    "    #Remove years without ESG Data\n",
    "    df = df[~(df.index.year == 2018)]\n",
    "    df = df[~(df.index.year == 2019)]\n",
    "    X, y = df.drop(columns=['Close']), df.Close.values\n",
    "\n",
    "    # Add ESG Data --------------------------------------\n",
    "\n",
    "    #Get Amount of data per year\n",
    "    X.loc[ X.index.year == 2018].sum(axis=1).count()\n",
    "    X.loc[ X.index.year == 2019].sum(axis=1).count()\n",
    "    count2020 = X.loc[ X.index.year == 2020].sum(axis=1).count()\n",
    "    count2021 =X.loc[ X.index.year == 2021].sum(axis=1).count()\n",
    "    count2022 =X.loc[ X.index.year == 2022].sum(axis=1).count()\n",
    "    count2023 =X.loc[ X.index.year == 2023].sum(axis=1).count()\n",
    "\n",
    "    # create Stacks of ESG values to be added to training data.\n",
    "\n",
    "    companyID = filename.split('_',1)[0]\n",
    "    print(companyID)\n",
    "\n",
    "    ESG2019 = df2019.loc[df2019.index == companyID]\n",
    "    dub = np.tile(ESG2019.values, (count2020, 1))\n",
    "    ESG2019_df = pd.DataFrame(dub, columns=ESG2019.columns)\n",
    "\n",
    "    ESG2020 = df2020.loc[df2020.index == companyID]\n",
    "    dub = np.tile(ESG2020.values, (count2021, 1))\n",
    "    ESG2020_df = pd.DataFrame(dub, columns=ESG2020.columns)\n",
    "\n",
    "    ESG2021 = df2021.loc[df2021.index == companyID]\n",
    "    dub = np.tile(ESG2021.values, (count2022, 1))\n",
    "    ESG2021_df = pd.DataFrame(dub, columns=ESG2021.columns)\n",
    "\n",
    "    ESG2022 = df2022.loc[df2022.index == companyID]\n",
    "    dub = np.tile(ESG2022.values, (count2023, 1))\n",
    "    ESG2022_df = pd.DataFrame(dub, columns=ESG2022.columns)\n",
    "\n",
    "\n",
    "    ESGData = pd.concat([ESG2019_df, ESG2020_df,ESG2021_df,ESG2022_df], ignore_index=True)\n",
    "    \n",
    "    ESGData= ESGData.reset_index(drop=True)\n",
    "    X = X.reset_index(drop=True)\n",
    "    \n",
    "    X_ESG = pd.concat([X, ESGData], axis=1)\n",
    "    print(X.shape)\n",
    "    print(ESGData.shape)\n",
    "    print(X_ESG.shape)\n",
    "\n",
    "    X_ESG = X_ESG.drop('Industry_code', axis=1)\n",
    "    X_ESG = X_ESG.fillna(0)\n",
    "    # Add ESG Data --------------------------------------\n",
    "\n",
    "    # NON ESG version\n",
    "    #if ESG:\n",
    "    #    X = X_ESG\n",
    "\n",
    "    # Data Preprocessing ----------------------------------------------------------------\n",
    "    mm = MinMaxScaler()\n",
    "    ss = StandardScaler()\n",
    "\n",
    "    #extra step to remove really all strings\n",
    "    X = X.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "    X = X.fillna(0)\n",
    "\n",
    "    # Basic Scaling of input \n",
    "    X_trans = ss.fit_transform(X)\n",
    "    y_trans = mm.fit_transform(y.reshape(-1, 1))\n",
    "    \n",
    "    # spliting the trainings data into sequences for training\n",
    "    def split_sequences(input_sequences, output_sequence, n_steps_in, n_steps_out):\n",
    "        X, y = list(), list() # instantiate X and y\n",
    "        for i in range(len(input_sequences)):\n",
    "            # find the end of the input, output sequence\n",
    "            end_ix = i + n_steps_in\n",
    "            out_end_ix = end_ix + n_steps_out - 1\n",
    "            # check if we are beyond the dataset\n",
    "            if out_end_ix +futureStep > len(input_sequences): break\n",
    "        \n",
    "            # gather input and output of the pattern\n",
    "            #seq_x, seq_y = input_sequences[i:end_ix], output_sequence[end_ix-1:out_end_ix, -1]\n",
    "            seq_x, seq_y = input_sequences[i:end_ix], output_sequence[futureStep+end_ix-1:futureStep+out_end_ix, -1]\n",
    "            X.append(seq_x), y.append(seq_y)\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    X_ss, y_mm = split_sequences(X_trans, y_trans, preview, predict)\n",
    "\n",
    "    print(X_ss.shape, y_mm.shape)\n",
    "\n",
    "    total_samples = len(X)\n",
    "    train_test_cutoff = total_samples-total #round(0.3 * total_samples)\n",
    "\n",
    "    #split between train and testing sets\n",
    "    testSamplesCount = round(0.3 * total_samples)\n",
    "\n",
    "    X_train = X_ss[:-testSamplesCount]\n",
    "    X_test = X_ss[-testSamplesCount:]\n",
    "\n",
    "    y_train = y_mm[:-testSamplesCount]\n",
    "    y_test = y_mm[-testSamplesCount:] \n",
    "\n",
    "    #print(\"Training Shape:\", X_train.shape, y_train.shape)\n",
    "    #print(\"Testing Shape:\", X_test.shape, y_test.shape) \n",
    "\n",
    "    X_train_tensors = Variable(torch.Tensor(X_train))\n",
    "    X_test_tensors = Variable(torch.Tensor(X_test))\n",
    "\n",
    "    y_train_tensors = Variable(torch.Tensor(y_train))\n",
    "    y_test_tensors = Variable(torch.Tensor(y_test))\n",
    "\n",
    "    selected_timestep = 0\n",
    "    # to adapte for non DL learning\n",
    "    #X_train_2d = X_train[:, selected_timestep, :]\n",
    "    #X_test_2d = X_train[:, selected_timestep, :]\n",
    "    #y_train_2d = X_train[:, selected_timestep, :]\n",
    "    #y_test_2d = X_train[:, selected_timestep, :]\n",
    "\n",
    "    #print(\"Training Shape:\", X_train.shape, y_train.shape)\n",
    "    #print(\"Testing Shape:\", X_test.shape, y_test.shape) \n",
    "\n",
    "    X_train_tensors = Variable(torch.Tensor(X_train))\n",
    "    X_test_tensors = Variable(torch.Tensor(X_test))\n",
    "\n",
    "    y_train_tensors = Variable(torch.Tensor(y_train))\n",
    "    y_test_tensors = Variable(torch.Tensor(y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        X_train_tensors_final = torch.reshape(X_train_tensors,   \n",
    "                                    (X_train_tensors.shape[0], preview, \n",
    "                                    X_train_tensors.shape[2]))\n",
    "        X_test_tensors_final = torch.reshape(X_test_tensors,  \n",
    "                                            (X_test_tensors.shape[0], preview, \n",
    "                                            X_test_tensors.shape[2])) \n",
    "    \n",
    "    except:\n",
    "    #    print(\"skipped invalid data\")\n",
    "            return -1\n",
    "\n",
    "    print(\"Training Shape:\", X_train_tensors_final.shape, y_train_tensors.shape)\n",
    "    print(\"Testing Shape:\", X_test_tensors_final.shape, y_test_tensors.shape) \n",
    "\n",
    "    # Training ------------------------------------------------------------------------------\n",
    "    '''\n",
    "    finalTestLoss = training_loop(n_epochs=n_epochs,\n",
    "        lstm=lstm,\n",
    "        optimiser=optimiser,\n",
    "        loss_fn=loss_fn,\n",
    "        X_train=X_train_tensors_final,\n",
    "        y_train=y_train_tensors,\n",
    "        X_test=X_test_tensors_final,\n",
    "        y_test=y_test_tensors)\n",
    "    '''\n",
    "\n",
    "\n",
    "    finalTestLoss, best_model = training_loop_nonDL(\n",
    "        X_train=X_train_tensors_final[:, 0, :],\n",
    "        y_train=y_train_tensors[:, 0],\n",
    "        X_test=X_test_tensors_final[:, 0, :],\n",
    "        y_test=y_test_tensors[:, 0])\n",
    "\n",
    "\n",
    "    # Ploting ------------------------------------------------------------------------------\n",
    "    \n",
    "    test_predict = best_model.predict(X_test_tensors_final[-1, 0, :].unsqueeze(0)) # get the last sample\n",
    "    #test_predict = test_predict.detach().numpy()\n",
    "    #test_predict = mm.inverse_transform(test_predict)\n",
    "    #test_predict = test_predict[0].tolist()\n",
    "\n",
    "    if plotting:\n",
    "        \"\"\" \n",
    "        df_X_ss = ss.transform(X) # old transformers\n",
    "        df_y_mm = mm.transform(df.Close.values.reshape(-1, 1)) # old transformers\n",
    "        # split the sequence\n",
    "        df_X_ss, df_y_mm = split_sequences(df_X_ss, df_y_mm, preview, predict)\n",
    "        # converting to tensors\n",
    "        df_X_ss = Variable(torch.Tensor(df_X_ss))\n",
    "        df_y_mm = Variable(torch.Tensor(df_y_mm))\n",
    "        # reshaping the dataset\n",
    "        df_X_ss = torch.reshape(df_X_ss, (df_X_ss.shape[0], preview, df_X_ss.shape[2]))\n",
    "\n",
    "        train_predict = lstm(df_X_ss) # forward pass\n",
    "        data_predict = train_predict.data.numpy() # numpy conversion\n",
    "        dataY_plot = df_y_mm.data.numpy()\n",
    "\n",
    "        data_predict = mm.inverse_transform(data_predict) # reverse transformation\n",
    "        dataY_plot = mm.inverse_transform(dataY_plot)\n",
    "        true, preds = [], []\n",
    "        for i in range(len(dataY_plot)):\n",
    "            true.append(dataY_plot[i][0])\n",
    "        for i in range(len(data_predict)):\n",
    "            preds.append(data_predict[i][0])\n",
    "        plt.figure(figsize=(10,6)) #plotting\n",
    "        plt.axvline(x=train_test_cutoff, c='r', linestyle='--') # size of the training set\n",
    "\n",
    "        plt.plot(true, label='Actual Data') # actual plot\n",
    "        plt.plot(preds, label='Predicted Data') # predicted plot\n",
    "        plt.title('Time-Series Prediction')\n",
    "        plt.legend()\n",
    "        plt.savefig(\"whole_plot.png\", dpi=300)\n",
    "        plt.show() \n",
    "        \"\"\"\n",
    "\n",
    "        # Ploting 2 ------------------------------------------------------------------------------\n",
    "\n",
    "        test_target = y_test_tensors[-1].detach().numpy() # last sample again\n",
    "        test_target = mm.inverse_transform(test_target.reshape(1, -1))\n",
    "        test_target = test_target[0].tolist()\n",
    "\n",
    "        plt.plot(test_target, label=\"Actual Data\")\n",
    "        plt.plot(test_predict, label=\"nonDL Predictions\")\n",
    "        plt.savefig(\"NonDL_plot.png\", dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "        # Ploting 2 ------------------------------------------------------------------------------\n",
    "\n",
    "        plt.figure(figsize=(10,6)) #plotting\n",
    "        a = [x for x in range(0, len(y))]\n",
    "        #a = [x for x in df.index]\n",
    "        plt.plot(a, y[0:], label='Actual data')\n",
    "        c = [x for x in range(len(y)-predict, len(y))]\n",
    "        #plt.plot(c, test_predict, label=f'One-shot multi-step prediction ({predict} days)')\n",
    "        #plt.axvline(x=len(y)-predict, c='r', linestyle='--')\n",
    "        plt.axvline(x=train_test_cutoff, c='r', linestyle='--')\n",
    "\n",
    "        plt.axvline(x=total_samples-count2023, c='b', linestyle='--')\n",
    "        plt.axvline(x=total_samples-count2023-count2022, c='b', linestyle='--')\n",
    "        plt.axvline(x=total_samples-count2023-count2022-count2021, c='b', linestyle='--')\n",
    "        plt.axvline(x=total_samples-count2023-count2022-count2021-count2020, c='b', linestyle='--')\n",
    "        plt.axvline(x=total_samples, c='b', linestyle='--')\n",
    "\n",
    "        plt.scatter(len(y), test_predict[0], color='red', marker='x', label='LongTermPrediction')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return finalTestLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1\n",
      "read file:CSI300_historical_Data/300750.SZ_historical_data_231116.csv\n",
      "300750.SZ\n",
      "(939, 6)\n",
      "(939, 14)\n",
      "(939, 20)\n",
      "(458, 241, 6) (458, 1)\n",
      "Training Shape: torch.Size([176, 241, 6]) torch.Size([176, 1])\n",
      "Testing Shape: torch.Size([282, 241, 6]) torch.Size([282, 1])\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nb/j2jdrzs95md121c1h0mksmz80000gq/T/ipykernel_18830/1930753754.py:74: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X = X.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "/var/folders/nb/j2jdrzs95md121c1h0mksmz80000gq/T/ipykernel_18830/1930753754.py:74: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X = X.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "iteration: 2\n",
      "read file:CSI300_historical_Data/600741.SH_historical_data_231116.csv\n",
      "600741.SH\n",
      "(939, 6)\n",
      "(939, 14)\n",
      "(939, 20)\n",
      "(458, 241, 6) (458, 1)\n",
      "Training Shape: torch.Size([176, 241, 6]) torch.Size([176, 1])\n",
      "Testing Shape: torch.Size([282, 241, 6]) torch.Size([282, 1])\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "/var/folders/nb/j2jdrzs95md121c1h0mksmz80000gq/T/ipykernel_18830/1930753754.py:74: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X = X.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "iteration: 3\n",
      "read file:CSI300_historical_Data/601699.SH_historical_data_231116.csv\n",
      "601699.SH\n",
      "(939, 6)\n",
      "(939, 14)\n",
      "(939, 20)\n",
      "(458, 241, 6) (458, 1)\n",
      "Training Shape: torch.Size([176, 241, 6]) torch.Size([176, 1])\n",
      "Testing Shape: torch.Size([282, 241, 6]) torch.Size([282, 1])\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "iteration: 4\n",
      "read file:CSI300_historical_Data/601766.SH_historical_data_231116.csv\n",
      "601766.SH\n",
      "(939, 6)\n",
      "(939, 14)\n",
      "(939, 20)\n",
      "(458, 241, 6) (458, 1)\n",
      "Training Shape: torch.Size([176, 241, 6]) torch.Size([176, 1])\n",
      "Testing Shape: torch.Size([282, 241, 6]) torch.Size([282, 1])\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nb/j2jdrzs95md121c1h0mksmz80000gq/T/ipykernel_18830/1930753754.py:74: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X = X.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "iteration: 5\n",
      "read file:CSI300_historical_Data/000002.SZ_historical_data_231116.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "/var/folders/nb/j2jdrzs95md121c1h0mksmz80000gq/T/ipykernel_18830/1930753754.py:74: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X = X.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000002.SZ\n",
      "(939, 6)\n",
      "(939, 14)\n",
      "(939, 20)\n",
      "(458, 241, 6) (458, 1)\n",
      "Training Shape: torch.Size([176, 241, 6]) torch.Size([176, 1])\n",
      "Testing Shape: torch.Size([282, 241, 6]) torch.Size([282, 1])\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "/var/folders/nb/j2jdrzs95md121c1h0mksmz80000gq/T/ipykernel_18830/1930753754.py:74: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X = X.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "iteration: 6\n",
      "read file:CSI300_historical_Data/002920.SZ_historical_data_231116.csv\n",
      "002920.SZ\n",
      "(939, 6)\n",
      "(939, 14)\n",
      "(939, 20)\n",
      "(458, 241, 6) (458, 1)\n",
      "Training Shape: torch.Size([176, 241, 6]) torch.Size([176, 1])\n",
      "Testing Shape: torch.Size([282, 241, 6]) torch.Size([282, 1])\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.0s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.0s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "/var/folders/nb/j2jdrzs95md121c1h0mksmz80000gq/T/ipykernel_18830/1930753754.py:74: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X = X.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "iteration: 7\n",
      "read file:CSI300_historical_Data/603986.SH_historical_data_231116.csv\n",
      "603986.SH\n",
      "(939, 6)\n",
      "(939, 14)\n",
      "(939, 20)\n",
      "(458, 241, 6) (458, 1)\n",
      "Training Shape: torch.Size([176, 241, 6]) torch.Size([176, 1])\n",
      "Testing Shape: torch.Size([282, 241, 6]) torch.Size([282, 1])\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.0s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.0s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "/var/folders/nb/j2jdrzs95md121c1h0mksmz80000gq/T/ipykernel_18830/1930753754.py:74: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X = X.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "iteration: 8\n",
      "read file:CSI300_historical_Data/600009.SH_historical_data_231116.csv\n",
      "600009.SH\n",
      "(939, 6)\n",
      "(939, 14)\n",
      "(939, 20)\n",
      "(458, 241, 6) (458, 1)\n",
      "Training Shape: torch.Size([176, 241, 6]) torch.Size([176, 1])\n",
      "Testing Shape: torch.Size([282, 241, 6]) torch.Size([282, 1])\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n",
      "[CV] END .................................................... total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "/var/folders/nb/j2jdrzs95md121c1h0mksmz80000gq/T/ipykernel_18830/1930753754.py:74: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X = X.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 9\n",
      "read file:CSI300_historical_Data/601100.SH_historical_data_231116.csv\n",
      "601100.SH\n",
      "(939, 6)\n",
      "(939, 14)\n",
      "(939, 20)\n",
      "(458, 241, 6) (458, 1)\n",
      "Training Shape: torch.Size([176, 241, 6]) torch.Size([176, 1])\n",
      "Testing Shape: torch.Size([282, 241, 6]) torch.Size([282, 1])\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "/var/folders/nb/j2jdrzs95md121c1h0mksmz80000gq/T/ipykernel_18830/1930753754.py:74: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X = X.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "iteration: 10\n",
      "read file:CSI300_historical_Data/601919.SH_historical_data_231116.csv\n",
      "601919.SH\n",
      "(939, 6)\n",
      "(939, 14)\n",
      "(939, 20)\n",
      "(458, 241, 6) (458, 1)\n",
      "Training Shape: torch.Size([176, 241, 6]) torch.Size([176, 1])\n",
      "Testing Shape: torch.Size([282, 241, 6]) torch.Size([282, 1])\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "/var/folders/nb/j2jdrzs95md121c1h0mksmz80000gq/T/ipykernel_18830/1930753754.py:74: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X = X.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "iteration: 11\n",
      "read file:CSI300_historical_Data/600884.SH_historical_data_231116.csv\n",
      "600884.SH\n",
      "(939, 6)\n",
      "(939, 14)\n",
      "(939, 20)\n",
      "(458, 241, 6) (458, 1)\n",
      "Training Shape: torch.Size([176, 241, 6]) torch.Size([176, 1])\n",
      "Testing Shape: torch.Size([282, 241, 6]) torch.Size([282, 1])\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "/var/folders/nb/j2jdrzs95md121c1h0mksmz80000gq/T/ipykernel_18830/1930753754.py:74: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X = X.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "iteration: 12\n",
      "read file:CSI300_historical_Data/601872.SH_historical_data_231116.csv\n",
      "601872.SH\n",
      "(939, 6)\n",
      "(939, 14)\n",
      "(939, 20)\n",
      "(458, 241, 6) (458, 1)\n",
      "Training Shape: torch.Size([176, 241, 6]) torch.Size([176, 1])\n",
      "Testing Shape: torch.Size([282, 241, 6]) torch.Size([282, 1])\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "/var/folders/nb/j2jdrzs95md121c1h0mksmz80000gq/T/ipykernel_18830/1930753754.py:74: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X = X.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "iteration: 13\n",
      "read file:CSI300_historical_Data/600436.SH_historical_data_231116.csv\n",
      "600436.SH\n",
      "(939, 6)\n",
      "(939, 14)\n",
      "(939, 20)\n",
      "(458, 241, 6) (458, 1)\n",
      "Training Shape: torch.Size([176, 241, 6]) torch.Size([176, 1])\n",
      "Testing Shape: torch.Size([282, 241, 6]) torch.Size([282, 1])\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.2s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.2s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.2s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.2s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.2s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.2s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "/var/folders/nb/j2jdrzs95md121c1h0mksmz80000gq/T/ipykernel_18830/1930753754.py:74: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X = X.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "iteration: 14\n",
      "read file:CSI300_historical_Data/603799.SH_historical_data_231116.csv\n",
      "603799.SH\n",
      "(939, 6)\n",
      "(939, 14)\n",
      "(939, 20)\n",
      "(458, 241, 6) (458, 1)\n",
      "Training Shape: torch.Size([176, 241, 6]) torch.Size([176, 1])\n",
      "Testing Shape: torch.Size([282, 241, 6]) torch.Size([282, 1])\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=0, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=3; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END regressor__l2_regularization=1, regressor__max_depth=5; total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "[CV] END .................................................... total time=   0.1s\n",
      "iteration: 15\n",
      "read file:CSI300_historical_Data/603369.SH_historical_data_231116.csv\n",
      "Final Statistic\n",
      "[0.03835159703624838, 0.12445575493491783, 0.11992789650773462, 0.1161104856346412, 0.02178635769421454, 0.07683158402136145, 0.045041058333735534, 0.027291996966833265, 0.016131578228014733, 0.002881448096273677, 0.1296515151021321, 0.08724434748946296, 0.0037025622396520126, 0.0866277480421104]\n",
      "Avarage Loss\n",
      "0.06400256645195233\n",
      "Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    safe = True\n",
    "    iteration = 0\n",
    "    finalloss = []\n",
    "    for filename in os.listdir('CSI300_historical_Data'):\n",
    "        iteration += 1\n",
    "        print(f\"iteration: {iteration}\")\n",
    "        f = os.path.join('CSI300_historical_Data', filename)\n",
    "        print('read file:' + f)\n",
    "        if iteration == 15:\n",
    "            break\n",
    "        \n",
    "        loss = TrainingIteration(False, f, filename)\n",
    "        if loss:\n",
    "            finalloss.append(loss)\n",
    "\n",
    "    print(\"Final Statistic\")\n",
    "    print(finalloss)\n",
    "    print(\"Avarage Loss\")\n",
    "    print((sum(finalloss) / len(finalloss)))\n",
    "    print(\"Finished\")\n",
    "\n",
    "    #if safe:\n",
    "        #torch.save(lstm.state_dict(), \"Model\")\n",
    "    #    joblib.dump(best_model, 'model_nonDL.pkl')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for filename in os.listdir('CSI300_historical_Data'):\n",
    "    f = os.path.join('CSI300_historical_Data', filename)\n",
    "\n",
    "preview = 241 # How many previous days to use for prediction\n",
    "predict = 1 # how many values in the future to predict\n",
    "futureStep = 241 # how far in the future to predict\n",
    "\n",
    "total = preview+predict\n",
    "\n",
    "df = pd.read_csv(f, index_col = 'Date', parse_dates=True)\n",
    "\n",
    "#Remove years without ESG Data\n",
    "df = df[~(df.index.year == 2018)]\n",
    "df = df[~(df.index.year == 2019)]\n",
    "X, y = df.drop(columns=['Close']), df.Close.values\n",
    "\n",
    "# Add ESG Data --------------------------------------\n",
    "\n",
    "#Get Amount of data per year\n",
    "X.loc[ X.index.year == 2018].sum(axis=1).count()\n",
    "X.loc[ X.index.year == 2019].sum(axis=1).count()\n",
    "count2020 = X.loc[ X.index.year == 2020].sum(axis=1).count()\n",
    "count2021 =X.loc[ X.index.year == 2021].sum(axis=1).count()\n",
    "count2022 =X.loc[ X.index.year == 2022].sum(axis=1).count()\n",
    "count2023 =X.loc[ X.index.year == 2023].sum(axis=1).count()\n",
    "\n",
    "# create Stacks of ESG values to be added to training data.\n",
    "\n",
    "companyID = filename.split('_',1)[0]\n",
    "print(companyID)\n",
    "\n",
    "ESG2019 = df2019.loc[df2019.index == companyID]\n",
    "dub = np.tile(ESG2019.values, (count2020, 1))\n",
    "ESG2019_df = pd.DataFrame(dub, columns=ESG2019.columns)\n",
    "\n",
    "ESG2020 = df2020.loc[df2020.index == companyID]\n",
    "dub = np.tile(ESG2020.values, (count2021, 1))\n",
    "ESG2020_df = pd.DataFrame(dub, columns=ESG2020.columns)\n",
    "\n",
    "ESG2021 = df2021.loc[df2021.index == companyID]\n",
    "dub = np.tile(ESG2021.values, (count2022, 1))\n",
    "ESG2021_df = pd.DataFrame(dub, columns=ESG2021.columns)\n",
    "\n",
    "ESG2022 = df2022.loc[df2022.index == companyID]\n",
    "dub = np.tile(ESG2022.values, (count2023, 1))\n",
    "ESG2022_df = pd.DataFrame(dub, columns=ESG2022.columns)\n",
    "\n",
    "\n",
    "ESGData = pd.concat([ESG2019_df, ESG2020_df,ESG2021_df,ESG2022_df], ignore_index=True)\n",
    "\n",
    "ESGData= ESGData.reset_index(drop=True)\n",
    "X = X.reset_index(drop=True)\n",
    "\n",
    "X_ESG = pd.concat([X, ESGData], axis=1)\n",
    "print(X.shape)\n",
    "print(ESGData.shape)\n",
    "print(X_ESG.shape)\n",
    "\n",
    "X_ESG = X_ESG.drop('Industry_code', axis=1)\n",
    "X_ESG = X_ESG.fillna(0)\n",
    "# Add ESG Data --------------------------------------\n",
    "\n",
    "if ESG:\n",
    "    X = X_ESG\n",
    "\n",
    "# Data Preprocessing ----------------------------------------------------------------\n",
    "mm = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n",
    "#extra step to remove really all strings\n",
    "X = X.applymap(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Basic Scaling of input \n",
    "X_trans = ss.fit_transform(X)\n",
    "y_trans = mm.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# spliting the trainings data into sequences for training\n",
    "def split_sequences(input_sequences, output_sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list() # instantiate X and y\n",
    "    for i in range(len(input_sequences)):\n",
    "        # find the end of the input, output sequence\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out - 1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix +futureStep > len(input_sequences): break\n",
    "    \n",
    "        # gather input and output of the pattern\n",
    "        #seq_x, seq_y = input_sequences[i:end_ix], output_sequence[end_ix-1:out_end_ix, -1]\n",
    "        seq_x, seq_y = input_sequences[i:end_ix], output_sequence[futureStep+end_ix-1:futureStep+out_end_ix, -1]\n",
    "        X.append(seq_x), y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_ss, y_mm = split_sequences(X_trans, y_trans, preview, predict)\n",
    "\n",
    "print(X_ss.shape, y_mm.shape)\n",
    "\n",
    "total_samples = len(X)\n",
    "train_test_cutoff = total_samples-total #round(0.3 * total_samples)\n",
    "\n",
    "#split between train and testing sets\n",
    "testSamplesCount = round(0.3 * total_samples)\n",
    "\n",
    "\n",
    "selected_timestep = 0\n",
    "\n",
    "\n",
    "X_train = X_ss[:-testSamplesCount]\n",
    "X_test = X_ss[-testSamplesCount:]\n",
    "\n",
    "y_train = y_mm[:-testSamplesCount]\n",
    "y_test = y_mm[-testSamplesCount:] \n",
    "\n",
    "\n",
    "X_train_2d = X_train[:, selected_timestep, :]\n",
    "X_test_2d = X_train[:, selected_timestep, :]\n",
    "y_train_2d = X_train[:, selected_timestep, :]\n",
    "y_test_2d = X_train[:, selected_timestep, :]\n",
    "\n",
    "#print(\"Training Shape:\", X_train.shape, y_train.shape)\n",
    "#print(\"Testing Shape:\", X_test.shape, y_test.shape) \n",
    "\n",
    "X_train_tensors = Variable(torch.Tensor(X_train_2d))\n",
    "X_test_tensors = Variable(torch.Tensor(X_test_2d))\n",
    "\n",
    "y_train_tensors = Variable(torch.Tensor(y_train_2d))\n",
    "y_test_tensors = Variable(torch.Tensor(y_test_2d))\n",
    "\n",
    "\n",
    "loss, best_model = TrainingIteration(False, f, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_tensors.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
